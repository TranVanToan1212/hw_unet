{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "!pip install torchgeometry\n",
    "!pip install torchvision\n",
    "from torchsummary import summary\n",
    "from torchgeometry.losses import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Resize, PILToTensor, ToPILImage, Compose, InterpolationMode, Normalize\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from collections import OrderedDict\n",
    "import wandb\n",
    "import random\n",
    "import copy\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 1e-04\n",
    "display_step = 50\n",
    "checkpoint_path = \"/kaggle/working/unet_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = Compose([    \n",
    "    Resize((224,224),\n",
    "    interpolation = InterpolationMode.BICUBIC, \n",
    "    antialias = True),\n",
    "])\n",
    "mask_transform = Compose([\n",
    "    Resize((224,224),\n",
    "    interpolation = InterpolationMode.NEAREST_EXACT)  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.OneOf([\n",
    "      A.RandomGamma(gamma_limit = (50, 120), p=1),  \n",
    "      A.CLAHE(clip_limit = 2),\n",
    "      A.Sharpen(p=1),\n",
    "      A.Equalize(p=1),  \n",
    "      A.ColorJitter(brightness = 0.5, contrast = 0.5, saturation = 2, hue = 0.05, p=1),  \n",
    "    ], p = 0.5),   \n",
    "    A.OneOf([\n",
    "      A.Perspective(keep_size = True, fit_output = False, p=1),\n",
    "      A.Rotate(limit=15, p=1, border_mode=cv2.BORDER_CONSTANT, value = 0, mask_value = 0)\n",
    "    ], p=0.5),  \n",
    "    A.ElasticTransform(p=0.5),\n",
    "    A.RandomSunFlare(num_flare_circles_lower=0, num_flare_circles_upper = 1, src_radius = 10, p = 0.3),\n",
    "])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClass(Dataset):\n",
    "    def __init__(self, images_list, masks_list, image_transform, mask_transform, train=False):\n",
    "        super(DataClass, self).__init__()\n",
    "        self.images_list = images_list\n",
    "        self.masks_list = masks_list\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.train = train\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images_list[index]\n",
    "        mask_path = self.masks_list[index]\n",
    "\n",
    "        data = Image.open(img_path)\n",
    "        label = Image.open(mask_path)\n",
    "\n",
    "        data = self.image_transform(data)\n",
    "        label = self.mask_transform(label)\n",
    "\n",
    "        data = np.array(data)\n",
    "        label = np.array(label)\n",
    "\n",
    "        if self.train == True: \n",
    "            A_transformed = A_transform(image = data, mask = label)\n",
    "            data = A_transformed['image']\n",
    "            label = A_transformed['mask']\n",
    "\n",
    "        data = Image.fromarray(data)\n",
    "        label = Image.fromarray(label)\n",
    "\n",
    "        data = PILToTensor()(data).type(torch.float32)\n",
    "        label = PILToTensor()(label)  / 255        \n",
    "        \n",
    "        data = Normalize(mean = (0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))(data)  \n",
    "\n",
    "        label = torch.where(label>0.65, 1.0, 0.0)  \n",
    "        label[2,:,:] = 0.0001 \n",
    "        label = torch.argmax(label, 0).type(torch.int64)  \n",
    "\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'resnet152'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = [0,1,2]\n",
    "ACTIVATION = 'softmax2d'\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"  \n",
    "masks_path = \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/\"\n",
    "\n",
    "images_list = os.listdir(images_path)\n",
    "masks_list = os.listdir(masks_path)\n",
    "\n",
    "images_list = [images_path + image_name for image_name in images_list]\n",
    "masks_list = [masks_path + mask_name for mask_name in masks_list]\n",
    "\n",
    "combined_list = list(zip(images_list, masks_list))\n",
    "random.shuffle(combined_list)\n",
    "\n",
    "train_images_list = images_list[:int(train_size*len(images_list))]\n",
    "valid_images_list = images_list[int(train_size*len(images_list)):]\n",
    "train_masks_list = masks_list[:int(train_size*len(masks_list))]\n",
    "valid_masks_list = masks_list[int(train_size*len(masks_list)):]\n",
    "\n",
    "train_set = DataClass(copy.deepcopy(train_images_list), copy.deepcopy(train_masks_list), image_transform, mask_transform, True)\n",
    "valid_set = DataClass(copy.deepcopy(valid_images_list), copy.deepcopy(valid_masks_list), image_transform, mask_transform, False)\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(input, target, smooth, weights):\n",
    "        \n",
    "    input_soft = F.softmax(input, dim=1)\n",
    "    # create the labels one hot tensor\n",
    "    target_one_hot = one_hot(target, num_classes=input.shape[1],\n",
    "                             device=input.device, dtype=input.dtype)\n",
    "\n",
    "    # compute the actual dice score\n",
    "    dims = (2, 3)\n",
    "    intersection = torch.sum(input_soft * target_one_hot, dims)\n",
    "    cardinality = torch.sum(input_soft + target_one_hot, dims)\n",
    "\n",
    "    dice_score = (2.*intersection)/(cardinality + smooth)\n",
    "\n",
    "    dice_score = torch.sum(dice_score * weights, dim = 1)\n",
    "\n",
    "    return torch.mean(dice_score) \n",
    "\n",
    "class CEDiceLoss(nn.Module):\n",
    "    def __init__(self, weights) -> None:\n",
    "        super(CEDiceLoss, self).__init__()\n",
    "        self.eps: float = 1e-6\n",
    "        self.weights: torch.Tensor = weights\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input: torch.Tensor,\n",
    "            target: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        if not torch.is_tensor(input):\n",
    "            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
    "                            .format(type(input)))\n",
    "        if not len(input.shape) == 4:\n",
    "            raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n",
    "                             .format(input.shape))\n",
    "        if not input.shape[-2:] == target.shape[-2:]:\n",
    "            raise ValueError(\"input and target shapes must be the same. Got: {}\"\n",
    "                             .format(input.shape, input.shape))\n",
    "        if not input.device == target.device:\n",
    "            raise ValueError(\n",
    "                \"input and target must be in the same device. Got: {}\" .format(\n",
    "                    input.device, target.device))\n",
    "        if not self.weights.shape[1] == input.shape[1]:\n",
    "            raise ValueError(\"The number of weights must equal the number of classes\")\n",
    "        if not torch.sum(self.weights).item() == 1:\n",
    "            raise ValueError(\"The sum of all weights must equal 1\")\n",
    "            \n",
    "        # cross entropy loss\n",
    "        celoss = nn.CrossEntropyLoss(self.weights)(input, target)\n",
    "        \n",
    "        dicescore = dice_score(input, target, self.eps, self.weights)\n",
    "        \n",
    "        return 1 - dicescore + celoss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print('model saved')\n",
    "\n",
    "def load_model(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print('model loaded')\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, \n",
    "          valid_dataloader,\n",
    "          epoch, display_step):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss_epoch = 0\n",
    "    test_loss_epoch = 0\n",
    "    train_dice_score_epoch = 0\n",
    "    test_dice_score_epoch = 0\n",
    "    \n",
    "    last_loss = 999999999\n",
    "    model.train()\n",
    "    for i, (data,targets) in enumerate(train_dataloader):\n",
    "        \n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        \n",
    "        loss = loss_function(outputs, targets.long())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        score = dice_score(outputs, targets.long(), 1e-6, weights)\n",
    "        train_loss_epoch += loss.item()\n",
    "        train_dice_score_epoch += score.item()\n",
    "        if (i+1) % display_step == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({}%)]\\tLoss: {:.4f}\\tScore: {:.4f}'.format(\n",
    "                epoch + 1, (i+1) * len(data), len(train_dataloader.dataset), 100 * (i+1) * len(data) / len(train_dataloader.dataset), loss.item(), score.item()\n",
    "            ))     \n",
    "                  \n",
    "    train_loss_epoch/= (i + 1)\n",
    "    train_dice_score_epoch /= (i + 1) \n",
    "    print(f\"Done epoch #{epoch+1}, time for this epoch: {time.time()-start_time}s\")\n",
    "                  \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            test_output = model(data)\n",
    "            test_loss = loss_function(test_output, target)\n",
    "            test_score = dice_score(test_output, target, 1e-6, weights)      \n",
    "            test_loss_epoch += test_loss.item()\n",
    "            test_dice_score_epoch += test_score.item()\n",
    "            print(test_loss.item(), test_score.item())\n",
    "              \n",
    "    test_loss_epoch/= (i+1)\n",
    "    test_dice_score_epoch/= (i+1)\n",
    "    \n",
    "    return train_loss_epoch , test_loss_epoch, train_dice_score_epoch, test_dice_score_epoch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.Tensor([[0.35, 0.58, 0.07]]).cuda()\n",
    "loss_function = CEDiceLoss(weights)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(\n",
    "    key = \"\"\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    project = \"PolypSegment_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_score = 0\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    train_loss_epoch = 0\n",
    "    test_loss_epoch = 0\n",
    "    train_dice_score_epoch = 0\n",
    "    test_dice_score_epoch = 0\n",
    "    (train_loss_epoch, test_loss_epoch, train_dice_score_epoch, test_dice_score_epoch) = train(train_dataloader, valid_dataloader, epoch, display_step)\n",
    "\n",
    "    if test_dice_score_epoch > last_score:    \n",
    "        save_model(model, optimizer, checkpoint_path)\n",
    "        last_score = test_dice_score_epoch    \n",
    "        \n",
    "    wandb.log({\"Train loss\": train_loss_epoch, \"Valid loss\": test_loss_epoch, \"Train score\": train_dice_score_epoch, \"Valid score\": test_dice_score_epoch})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data, label) in enumerate(train_dataloader):\n",
    "    img = data\n",
    "    mask = label\n",
    "    break\n",
    "    \n",
    "fig, arr = plt.subplots(4, 3, figsize=(16, 12))\n",
    "arr[0][0].set_title('Image')\n",
    "arr[0][1].set_title('Segmentation')\n",
    "arr[0][2].set_title('Predict')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict = model(img)\n",
    "    \n",
    "for i in range(4):\n",
    "    arr[i][0].imshow(img[i].permute(1, 2, 0));\n",
    "    \n",
    "    arr[i][1].imshow(F.one_hot(mask[i]).float())\n",
    "    \n",
    "    arr[i][2].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Resize((224,224),\n",
    "        interpolation = InterpolationMode.BICUBIC, \n",
    "        antialias = True),\n",
    "    PILToTensor(),\n",
    "])        \n",
    "\n",
    "class UNetTestDataClass(Dataset):\n",
    "    def __init__(self, images_path, transform):\n",
    "        super(UNetTestDataClass, self).__init__()\n",
    "        \n",
    "        images_list = os.listdir(images_path)\n",
    "        images_list = [images_path+i for i in images_list]\n",
    "        \n",
    "        self.images_list = images_list\n",
    "        self.transform = transform   \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images_list[index]\n",
    "        data = Image.open(img_path)\n",
    "        h = data.size[1]\n",
    "        w = data.size[0]\n",
    "        \n",
    "        data = self.transform(data)\n",
    "        data = data.type(torch.float32)\n",
    "        data = Normalize(mean = (0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))(data)        \n",
    "\n",
    "        return data, img_path, h, w\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/kaggle/input/bkai-igh-neopolyp/test/test/'\n",
    "unet_test_dataset = UNetTestDataClass(path, transform)\n",
    "test_dataloader = DataLoader(unet_test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "for i, (data, path, h, w) in enumerate(test_dataloader):\n",
    "    img = data\n",
    "    break\n",
    "    \n",
    "fig, arr = plt.subplots(5, 2, figsize=(16, 12))\n",
    "arr[0][0].set_title('Image');\n",
    "arr[0][1].set_title('Predict');\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict = model(img)\n",
    "\n",
    "for i in range(5):\n",
    "    arr[i][0].imshow(img[i].permute(1, 2, 0));\n",
    "    arr[i][1].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "if not os.path.isdir(\"/kaggle/working/predicted_masks\"):\n",
    "    os.mkdir(\"/kaggle/working/predicted_masks\")\n",
    "for _, (img, path, H, W) in enumerate(test_dataloader):\n",
    "    a = path\n",
    "    b = img\n",
    "    h = H\n",
    "    w = W\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predicted_mask = model(b)\n",
    "    for i in range(len(a)):\n",
    "        image_id = a[i].split('/')[-1].split('.')[0]\n",
    "        filename = image_id + \".png\"\n",
    "        mask2img = Resize((h[i].item(), w[i].item()), interpolation=InterpolationMode.NEAREST_EXACT)(ToPILImage()(F.one_hot(torch.argmax(predicted_mask[i], 0)).permute(2, 0, 1).float()))\n",
    "        mask2img.save(os.path.join(\"/kaggle/working/predicted_masks/\", filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 0] = 255\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    \n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def mask2string(dir):\n",
    "    ## mask --> string\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "MASK_DIR_PATH = '/kaggle/working/predicted_masks' # change this to the path to your output mask folder\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "df.to_csv(r'output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
